{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JAustin/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/JAustin/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def import_from_csv(path, pixel_depth, length, class_num):\n",
    "    train_database = np.genfromtxt('{}'.format(path), delimiter=\",\", dtype=int)[1:,:]\n",
    "    train_labels = train_database[:,0].reshape(length,)\n",
    "    training_labels = np.eye(class_num)[train_labels]\n",
    "    training_data = np.delete(train_database,0,1)\n",
    "    return normalize(training_data, pixel_depth), training_labels, train_labels\n",
    "\n",
    "def normalize(image_data, pixel_depth):\n",
    "    data = (image_data - pixel_depth / 2) / pixel_depth\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "training_data, training_labels, correct_index = import_from_csv('/Users/JAustin/Desktop/MNIST/train.csv', 255, 42000, 10)\n",
    "\n",
    "test_labels = np.eye(10)[np.genfromtxt('{}'.format('/Users/JAustin/Desktop/MNIST/results_net4.csv'), delimiter=\",\", dtype=int)[1:, 1]]\n",
    "test_data = normalize(np.genfromtxt('{}'.format('/Users/JAustin/Desktop/MNIST/test.csv'), delimiter=\",\", dtype=int)[1:, :], 255)\n",
    "\n",
    "\n",
    "#training_data = np.random.rand(20000, 784)\n",
    "#correct_index = np.random.choice(10, np.shape(training_data)[0])\n",
    "#training_labels = np.eye(10)[correct_index]\n",
    "\n",
    "#training_data = np.random.rand(10000, 784)\n",
    "#training_weights = np.random.rand(10, 784)\n",
    "#X = np.dot(training_data, training_weights.T)\n",
    "#training_labels = X / np.sum(X, axis=1).reshape(10000,1)\n",
    "\n",
    "data_size = np.shape(training_data)[0] # 20000\n",
    "num_params = np.shape(training_data)[1] # 784\n",
    "num_classes = np.shape(training_labels)[1] # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1)[:,None]\n",
    "\n",
    "def predict(data, batch_size, weights, biases):\n",
    "    index = np.random.choice(len(data), batch_size, replace=False)\n",
    "    output = np.dot(data[index], weights.T) + biases.T #np.dot(weights[:,np.newaxis], np.transpose(data[index])) + biases\n",
    "    return index, softmax(output)\n",
    "\n",
    "def evaluate(data, labels, weights, biases, batch_size):\n",
    "    index = np.random.choice(len(data), batch_size, replace=False)\n",
    "    accuracy = (np.argmax(softmax(np.dot(data[index], weights.T) + biases.T), axis=1)==np.argmax(labels[index], axis=1)).sum() * 100 / batch_size\n",
    "    print(\"The accuracy of your model is %s%%!\" % accuracy)\n",
    "    return accuracy, index\n",
    "\n",
    "def conditional_evaluate(data, labels, weights, biases, batch_size, threshold):\n",
    "    index = np.random.choice(len(data), batch_size, replace=False)\n",
    "    prediction = np.argmax(softmax(np.dot(data[index], weights.T) + biases.T), axis=1)\n",
    "    accuracy = (np.argmax(softmax(np.dot(data[index], weights.T) + biases.T), axis=1) == np.argmax(labels[index],axis=1)).sum() * 100 / batch_size\n",
    "    unsure = np.where(np.max(softmax(np.dot(data[index], weights.T) + biases.T), axis=1) < threshold)[0]\n",
    "    print(\"The accuracy of your model is %s%%! The model is unsure about %s%%\" % (accuracy, len(unsure)*100/batch_size))\n",
    "    return accuracy, index, unsure, prediction\n",
    "\n",
    "def check(data, prediction, index, dim=28, test_labels = None):\n",
    "    img = data[index].reshape(dim, dim)\n",
    "    print('The model thinks this number is a %s.' % prediction[index])\n",
    "    if not test_labels is None: print('The provided labels think this number is a %s' % np.argmax(test_labels[index]))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "def check_unsure(arr):\n",
    "    for i in range(len(arr)):\n",
    "        check(test_data, prediction, arr[i], test_labels = test_labels)\n",
    "        plt.figure(i+1)\n",
    "\n",
    "def gradient_descent(data, labels, weights, biases, batch_size, iterations, learning_rate, momentum_rate):\n",
    "    weight_momentum = np.zeros_like(weights)\n",
    "    bias_momentum = np.zeros_like(biases)\n",
    "    gamma = momentum_rate\n",
    "    for i in range(iterations):\n",
    "        temp_weights = weights - gamma*weight_momentum\n",
    "        temp_biases = biases - gamma*bias_momentum\n",
    "        index, prediction = predict(data, batch_size, temp_weights, temp_biases)\n",
    "        loss = - np.tensordot(labels[index], np.log(prediction), axes=2) / batch_size # + .1*np.linalg.norm(weights)**2 # cross entropy loss\n",
    "        if i % 50 == 0: print(\"Loss at step %s is %s\" % (i, loss))\n",
    "        if i % 1000 == 0: conditional_evaluate(test_data, test_labels, weights, biases, len(test_data), threshold)\n",
    "        error_arr = prediction - labels[index]\n",
    "        dW = np.sum(error_arr[..., None] * data[index][:, None, :], axis=0) / batch_size\n",
    "        dB = np.sum(error_arr, axis=0)[:, None] / batch_size\n",
    "        weight_momentum = gamma*weight_momentum + learning_rate[i]*dW\n",
    "        bias_momentum = gamma*bias_momentum + learning_rate[i]*dB\n",
    "        weights -= weight_momentum\n",
    "        biases -= bias_momentum\n",
    "\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0 is 9.57082447733\n",
      "The accuracy of your model is 10.0321428571%! The model is unsure about 0.014285714285714285%\n",
      "Loss at step 50 is 1.23337217589\n",
      "Loss at step 100 is 1.02007426723\n",
      "Loss at step 150 is 0.446568194512\n",
      "Loss at step 200 is 0.781520486338\n",
      "Loss at step 250 is 0.112080771539\n",
      "Loss at step 300 is 0.272842792415\n",
      "Loss at step 350 is 0.297163506161\n",
      "Loss at step 400 is 0.432457931862\n",
      "Loss at step 450 is 0.553265024254\n",
      "Loss at step 500 is 0.899125521802\n",
      "Loss at step 550 is 0.331779636055\n",
      "Loss at step 600 is 0.204641253432\n",
      "Loss at step 650 is 0.181484376669\n",
      "Loss at step 700 is 0.535003007903\n",
      "Loss at step 750 is 0.222346568193\n",
      "Loss at step 800 is 0.408018831666\n",
      "Loss at step 850 is 0.223059674908\n",
      "Loss at step 900 is 0.191663323958\n",
      "Loss at step 950 is 0.330562802621\n",
      "Loss at step 1000 is 0.248491986914\n",
      "The accuracy of your model is 91.2714285714%! The model is unsure about 0.02857142857142857%\n",
      "Loss at step 1050 is 0.251377831019\n",
      "Loss at step 1100 is 0.346519577912\n",
      "Loss at step 1150 is 0.478623234014\n",
      "Loss at step 1200 is 0.184234424446\n",
      "Loss at step 1250 is 0.578296582937\n",
      "Loss at step 1300 is 0.479069209979\n",
      "Loss at step 1350 is 0.198641896381\n",
      "Loss at step 1400 is 0.183357112592\n",
      "Loss at step 1450 is 0.264266543772\n",
      "Loss at step 1500 is 0.587150251151\n",
      "Loss at step 1550 is 0.304531592112\n",
      "Loss at step 1600 is 0.268383404427\n",
      "Loss at step 1650 is 0.309907913211\n",
      "Loss at step 1700 is 0.414986052427\n",
      "Loss at step 1750 is 0.277291169347\n",
      "Loss at step 1800 is 0.143364671999\n",
      "Loss at step 1850 is 0.312369798647\n",
      "Loss at step 1900 is 0.102453464729\n",
      "Loss at step 1950 is 0.328474846175\n",
      "Loss at step 2000 is 0.27766651775\n",
      "The accuracy of your model is 92.0571428571%! The model is unsure about 0.07142857142857142%\n",
      "Loss at step 2050 is 0.248733727162\n",
      "Loss at step 2100 is 0.500999849184\n",
      "Loss at step 2150 is 0.283739611313\n",
      "Loss at step 2200 is 0.585654700891\n",
      "Loss at step 2250 is 0.178575540384\n",
      "Loss at step 2300 is 0.113511710672\n",
      "Loss at step 2350 is 0.174907595866\n",
      "Loss at step 2400 is 0.275746946051\n",
      "Loss at step 2450 is 0.34173860989\n",
      "Loss at step 2500 is 0.332212498856\n",
      "Loss at step 2550 is 0.241820505162\n",
      "Loss at step 2600 is 0.140195418231\n",
      "Loss at step 2650 is 0.20921419628\n",
      "Loss at step 2700 is 0.220011259932\n",
      "Loss at step 2750 is 0.478480090572\n",
      "Loss at step 2800 is 0.306992729198\n",
      "Loss at step 2850 is 0.196727952986\n",
      "Loss at step 2900 is 0.302459691594\n",
      "Loss at step 2950 is 0.177587561936\n",
      "Loss at step 3000 is 0.256240389918\n",
      "The accuracy of your model is 92.3392857143%! The model is unsure about 0.05%\n",
      "Loss at step 3050 is 0.120301292143\n",
      "Loss at step 3100 is 0.226196145663\n",
      "Loss at step 3150 is 0.174000787889\n",
      "Loss at step 3200 is 0.256072983484\n",
      "Loss at step 3250 is 0.0663755772895\n",
      "Loss at step 3300 is 0.380404233799\n",
      "Loss at step 3350 is 0.221360553905\n",
      "Loss at step 3400 is 0.406427218044\n",
      "Loss at step 3450 is 0.255785533492\n",
      "Loss at step 3500 is 0.135250281756\n",
      "Loss at step 3550 is 0.434539542555\n",
      "Loss at step 3600 is 0.204455065255\n",
      "Loss at step 3650 is 0.104399259683\n",
      "Loss at step 3700 is 0.300698638422\n",
      "Loss at step 3750 is 0.238011850096\n",
      "Loss at step 3800 is 0.460601532575\n",
      "Loss at step 3850 is 0.271730568374\n",
      "Loss at step 3900 is 0.16159103202\n",
      "Loss at step 3950 is 0.14285121007\n",
      "Loss at step 4000 is 0.506469145155\n",
      "The accuracy of your model is 92.7214285714%! The model is unsure about 0.05%\n",
      "Loss at step 4050 is 0.332582482094\n",
      "Loss at step 4100 is 0.345441749187\n",
      "Loss at step 4150 is 0.379741426108\n",
      "Loss at step 4200 is 0.180729906567\n",
      "Loss at step 4250 is 0.251492894795\n",
      "Loss at step 4300 is 0.2343918216\n",
      "Loss at step 4350 is 0.231659332864\n",
      "Loss at step 4400 is 0.254400925091\n",
      "Loss at step 4450 is 0.193528410569\n",
      "Loss at step 4500 is 0.0816524711414\n",
      "Loss at step 4550 is 0.0997055896112\n",
      "Loss at step 4600 is 0.156636668202\n",
      "Loss at step 4650 is 0.118941571734\n",
      "Loss at step 4700 is 0.170132321129\n",
      "Loss at step 4750 is 0.119048635195\n",
      "Loss at step 4800 is 0.363881613079\n",
      "Loss at step 4850 is 0.177563780944\n",
      "Loss at step 4900 is 0.177072886297\n",
      "Loss at step 4950 is 0.126309119643\n",
      "The accuracy of your model is 93.75%! The model is unsure about 1.5625%\n"
     ]
    }
   ],
   "source": [
    "weights = np.random.rand(num_classes, num_params) # or randn\n",
    "biases = np.random.rand(num_classes, 1)\n",
    "\n",
    "batch_size = 64\n",
    "iterations = 5000\n",
    "\n",
    "momentum_rate = .9\n",
    "threshold = .3\n",
    "\n",
    "# learning_rate = np.array([.01*(1 - x/iterations) for x in range(iterations)]) # linear learning rate\n",
    "learning_rate = .3*np.exp(-5*np.arange(0,iterations)/iterations) # exponential learning rate\n",
    "# learning_rate = .01 * np.ones(iterations) # constant learning rate\n",
    "\n",
    "new_weights, new_biases = gradient_descent(training_data, training_labels, weights, biases, batch_size, iterations, learning_rate, momentum_rate)\n",
    "accuracy, index, unsure, prediction = conditional_evaluate(training_data, training_labels, new_weights, new_biases, batch_size, threshold) # probably should be larger than batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "(5575,)\n",
      "(22425, 784)\n",
      "(22425, 10)\n",
      "The accuracy of your model is 92.7447045708%!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.744704570791527, array([1842, 1796, 9018, ..., 4958, 4427, 5936]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(unsure)\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(unsure))\n",
    "print(np.shape(np.delete(test_data,unsure, axis=0)))\n",
    "print(np.shape(np.delete(test_labels,unsure,axis=0)))\n",
    "evaluate(np.delete(test_data, unsure, axis=0), np.delete(test_labels,unsure,axis=0), weights, biases, len(np.delete(test_data,unsure,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your model is 93.0214285714%! The model is unsure about 19.910714285714285%\n",
      "(5575,)\n"
     ]
    }
   ],
   "source": [
    "threshold = .9\n",
    "\n",
    "accuracy, index, unsure, prediction = conditional_evaluate(training_data, training_labels, new_weights, new_biases, len(test_data), threshold) # probably should be larger than batch_size\n",
    "\n",
    "print(np.shape(unsure))\n",
    "\n",
    "#test_labels[unsure[0]]\n",
    "#prediction[unsure[0]]\n",
    "#plt.imshow(test_data[unsure[0]].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
